[{"authors":null,"categories":null,"content":"I am Ran Zhu, a graduate candidate (supervised by Prof. Zhuoling Xiao) studying in Communication and information system in the Department of Internet of Things Engineering, UESTC (Chengdu).\nMy research interests lie in indoor pedestrian positioning and intelligent navigation for autonomous robots, especially about PDR, visual odometry, and visual SLAM. Previously I had been working on human activity recognition using smartphones and Zero velocity detection in ZUPT based on inertial for pedestrian navigation. I design new algorithms (increasing machine and deep learning based) and apply these innovations to solving these issues.\nCurrently, I am investigating how to localize people and objects in environments where technologies like GPS fail, such as underground or indoors. For people positioning, my work is to address the map matching problem of inertial navigation by leveraging architectural constraints and visual information when there is no starting point. For robot navigation, my research aims to build an intelligent robotic system that can more efficiently deal with the traditional SLAM problems by combining traditional methods and deep learning.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/author/ran-zhu-%E6%9C%B1%E7%84%B6/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/ran-zhu-%E6%9C%B1%E7%84%B6/","section":"authors","summary":"I am Ran Zhu, a graduate candidate (supervised by Prof. Zhuoling Xiao) studying in Communication and information system in the Department of Internet of Things Engineering, UESTC (Chengdu).\nMy research interests lie in indoor pedestrian positioning and intelligent navigation for autonomous robots, especially about PDR, visual odometry, and visual SLAM.","tags":null,"title":"Ran Zhu (朱然)","type":"authors"},{"authors":["Ran Zhu, Mingkun Yang, Wang Liu, Rujun Song, Zhuoling Xiao, Bo Yan"],"categories":null,"content":"","date":1569888000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569888000,"objectID":"2af9733828cb92f53c9f2063e306d07d","permalink":"/publication/project4/","publishdate":"2019-10-01T00:00:00Z","relpermalink":"/publication/project4/","section":"publication","summary":"Inertial navigation system (INS) is a practical method for indoor pedestrian navigation without pre-installation of infrastructure. Based on the ...","tags":["Source Themes"],"title":"DeepAVO: Efficient Pose Refining with Feature Distilling for Deep Visual Odometry","type":"publication"},{"authors":null,"categories":null,"content":"To build an intelligent robotic positioning system that can more efficiently deal with the traditional SLAM problems such as camera calibration, monocular scale ambiguity, we explore a novel strategy for performing visual ego-motion estimation based on deep learning. Here, we extend the model into four branches focusing on pixels movement in different directions in the optical flow and then regress the global feature concatenated from the four outputs to obtain F2F motion estimation. In particular, features extracted by each branch have been distilled by using the attention mechanism to refine estimation. Experiments on the KITTI and Malaga benchmark datasets demonstrate that the proposed model outperforms state-of-the-art monocular methods by a large margin and produces competitive results against the classic stereo VO algorithm, which also highlights its promising generalization ability.\n","date":1569888000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569888000,"objectID":"68fe1e900090392e3d2a97574964bc5a","permalink":"/project/project3/","publishdate":"2019-10-01T00:00:00Z","relpermalink":"/project/project3/","section":"project","summary":"Efficient pose estimation with featuredistilling for deep visual odometry.","tags":["Mobile Robotics"],"title":"Visual Odometry","type":"project"},{"authors":null,"categories":null,"content":"Loop Closure Detection (LCD), considered a key optimization part in the visual SLAM system, aims to recognize the places where a mobile robot previously visited. Correct loop closure detection benefits visual SLAM systems a lot because it can significantly reduce the position errors that accumulate over time. It enables the system to build a consistent map of the environment. We introduce the adaptive weighted similarity matrix by combining the feature extraction module and similarity measurement module to focus on changing appearance over time. Experiments on three typical open datasets are conducted to verify the feasibility of the proposed model.\n","date":1568505600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1568505600,"objectID":"e9f2758a8cec6fe970889b4e8ea07727","permalink":"/project/project4/","publishdate":"2019-09-15T00:00:00Z","relpermalink":"/project/project4/","section":"project","summary":"A loop closure detection method using adaptive weighted similarity matrix.","tags":["Mobile Robotics"],"title":"Loop Closure Detection","type":"project"},{"authors":["Ying Li, Ran Zhu, Mingkun Yang, Zhuoling Xiao, Yuhan Zhang, Bo Yan"],"categories":null,"content":"","date":1568505600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1568505600,"objectID":"6639d817c449fc2a1c77015a76af5142","permalink":"/publication/project5/","publishdate":"2019-09-15T00:00:00Z","relpermalink":"/publication/project5/","section":"publication","summary":"Loop Closure Detection (LCD), also known as the place recognition of pre-visited areas, is a significant optimization module in visual simultaneous ...","tags":["Source Themes"],"title":"MetricNet: A Loop Closure Detection Method for Appearance Variation using Adaptive Weighted Similarity Matrix","type":"publication"},{"authors":null,"categories":null,"content":"This work focuses on map-based deployment-independent indoor positioning. Due to the fact that most existing map matching methods rely on the external information of prior site survey or initial positions provided by users, we explore a novel strategy for performing deployment-independent indoor positioning without considering start points. Here, we adopt easily accessible information such as floor plan and real-time video captured by smartphones to determine the location of the pedestrian for the following tracking.\n","date":1568419200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1568419200,"objectID":"80a10a88f419cd9548ab4da835f4ac80","permalink":"/project/project5/","publishdate":"2019-09-14T00:00:00Z","relpermalink":"/project/project5/","section":"project","summary":"Without start points\u0026#58 Indoor positioning using architectural constraints.","tags":["Pedestrian Positioning"],"title":"Visual Inertial Map Matching","type":"project"},{"authors":["Kunxin Li, Mingkun Yang, Ran Zhu, Zhuoling Xiao, Bo Yan"],"categories":null,"content":"","date":1568419200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1568419200,"objectID":"9db891cf0fb71413d4b1aa26b252ba48","permalink":"/publication/project6/","publishdate":"2019-09-14T00:00:00Z","relpermalink":"/publication/project6/","section":"publication","summary":"Deployment-independent indoor localization methods, such as inertial tracking and vision-based tracking have been popular for years for they require no extra ...","tags":["Source Themes"],"title":"Visual Inertial Map Matching for Indoor Positioning using Architectural Constraints","type":"publication"},{"authors":["Mingkun Yang, Ran Zhu, Zhuoling Xiao, Bo Yan"],"categories":null,"content":"","date":1567296000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567296000,"objectID":"6252b5ee07edd8fe83e93d49357d6dc0","permalink":"/publication/project3/","publishdate":"2019-09-01T00:00:00Z","relpermalink":"/publication/project3/","section":"publication","summary":"Inertial navigation system (INS) is a practical method for indoor pedestrian navigation without pre-installation of infrastructure. Based on the fundamentals ...","tags":["Source Themes"],"title":"Symmetrical-Net: Adaptive Zero Velocity Detection for ZUPT-Aided Pedestrian Navigation System","type":"publication"},{"authors":null,"categories":null,"content":"Based on the fundamentals of human bipedal motion, Zero Velocity Update (ZUPT) is a pervasive approach in Pedestrian dead reckoning (PDR) to tackle the accumulated error of IMU. The key to ZUPT is precise zero velocity detection that distinguishes the stationary phase from each stride. Besides, due to the complex differences in pedestrian motion patterns, the hope is that the zero velocity detector becomes robust for various individuals. We present a novel approach leveraging deep learning (DL) to detect zero velocity adaptively. Trained by massive foot-mounted IMU data from different individuals, the symmetrical Recurrent Convolutional Neural Network (RCNNs) can effectively learn the gait law because the model takes the information from forward to backward of the undetermined time instant into consideration.\n","date":1567296000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567296000,"objectID":"5302252e8f3539312931c7276cda35e3","permalink":"/project/project2/","publishdate":"2019-09-01T00:00:00Z","relpermalink":"/project/project2/","section":"project","summary":"Adaptive zero velocity detection for ZUPT-aided pedestrian navigation system.","tags":["Pedestrian Positioning"],"title":"Zero Velocity Detection","type":"project"},{"authors":["Ran Zhu, Zhuoling Xiao, Ying Li, Mingkun Yang, Yawen Tan, Liang Zhou, Shuisheng Lin, Hongkai Wen"],"categories":null,"content":"","date":1560124800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1560124800,"objectID":"9cca770e21ad764557fa2f543c1f0ea8","permalink":"/publication/project2/","publishdate":"2019-05-21T00:00:00Z","relpermalink":"/publication/project2/","section":"publication","summary":"The ubiquity of smartphones and their rich set of on-board sensors have created many exciting new opportunities, where smartphones are used as powerful ...","tags":["Source Themes"],"title":"Efficient Human Activity Recognition Solving the Confusing Activities via Deep Ensemble Learning","type":"publication"},{"authors":null,"categories":null,"content":"The proliferation of smartphones has significantly facilitated people’s life, and diverse and powerful embedded sensors make the smartphone a ubiquitous platform to acquire and analyze data, which also provides great potential for efficient human activity recognition. We propose a learning-based ensemble model to improve the recognition accuracy of human activities, especially those that are easily confused. In order to make the model more robust and generalized, a huge amount of motion data, including 100 participants aging from 12 to 51, is collected using ordinary smartphones at a sampling rate of 50Hz. This dataset contains 7 motion modes in 4 smartphone placements under 2 different collection platforms (IOS and Android).\n","date":1560124800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1560124800,"objectID":"9b74b6d80c74c11210b876d3c28bd186","permalink":"/project/project1/","publishdate":"2019-06-10T00:00:00Z","relpermalink":"/project/project1/","section":"project","summary":"An efficient deep Ensemble method to recognize confusing activities.","tags":["Deep Learning"],"title":"Human Activity Recognition","type":"project"},{"authors":[],"categories":[],"content":"Deep Ensemble Learning For HAR Using Smartphone Conference PDF | Journal PDF\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot;\rif porridge == \u0026quot;blueberry\u0026quot;:\rprint(\u0026quot;Eating...\u0026quot;)\r  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}}\r{{% fragment %}} **Two** {{% /fragment %}}\r{{% fragment %}} Three {{% /fragment %}}\r Press Space to play!\nOne  Two  Three \n A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}}\r- Only the speaker can read these notes\r- Press `S` key to view\r{{% /speaker_note %}}\r Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/media/boards.jpg\u0026quot; \u0026gt;}}\r{{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}}\r{{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}\r  Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1,\r.reveal section h2,\r.reveal section h3 {\rcolor: navy;\r}\r  Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to HAR.","tags":[],"title":"Slides","type":"slides"},{"authors":["Ran Zhu, Zhuoling Xiao, Mo Cheng, Liang Zhou, Bo Yan, Shuisheng Lin, Hongkai Wen"],"categories":null,"content":"","date":1542672000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1542672000,"objectID":"10f9da1bc09054594ee847d50cb3b255","permalink":"/publication/project7/","publishdate":"2018-11-20T00:00:00Z","relpermalink":"/publication/project7/","section":"publication","summary":"The ubiquity of smartphones and their rich set of onboard sensors have created many exciting new opportunities. One important application is activity recognition ...","tags":["Source Themes"],"title":"Deep Ensemble Learning for Human Activity Recognition Using Smartphone","type":"publication"}]